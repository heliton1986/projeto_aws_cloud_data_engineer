{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qamwyb0eJWo5"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoPmTv-ZKmM-"
      },
      "source": [
        "### 1 - Inicialmente iremos preparar o ambiente, definindo o diretório onde nosso código será desenvolvido.\n",
        "### Para este diretório iremos copiar o arquivo nomes_aleatorios.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6RKV5ruJMtB"
      },
      "outputs": [],
      "source": [
        "#  Após, em nosso script Python, devemos importar as bibliotecas necessárias:\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext, SQLContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zp2O3_jJROz"
      },
      "outputs": [],
      "source": [
        "# Aplicando as bibliotecas do Spark, podemos definir a Spark Session e sobre ela definir o Context para habilitar o módulo SQL\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\")\\\n",
        "    .appName(\"Exercicio Intro\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1RpLqjtJeHG",
        "outputId": "ff507eca-01ae-4525-d7d3-b6c9b4e0c65e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|              _c0|\n",
            "+-----------------+\n",
            "|      Rodger Keys|\n",
            "|       James Cole|\n",
            "|    Vanessa Boyle|\n",
            "|Harriet Berringer|\n",
            "|      Ruby Oleary|\n",
            "+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Nesta etapa, adicione código para ler o arquivo nomes_aleatorios.txt através do comando spark.read.csv. Carregue-o para dentro de um dataframe chamado df_nomes e, por fim,\n",
        "# liste algumas linhas através do método show. Exemplo: df_nomes.show(5)\n",
        "\n",
        "df_nomes = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/Secao_4/nomes_aleatorios.txt')\n",
        "\n",
        "df_nomes.show(5)\n",
        "type(df_nomes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C676eHHLBfZ"
      },
      "source": [
        "### 2 - No Python, é possível acessar uma coluna de um objeto dataframe pelo atributo (por exemplo df_nomes.nome) ou por índice (df_nomes['nome']). Enquanto a primeira forma é conveniente para a exploração de dados interativos, você deve usar o formato de índice, pois caso algum nome de coluna não esteja de acordo seu código irá falhar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGDGQxXRK7gy",
        "outputId": "4fef932e-4364-4fb2-ff4b-be919627690c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Como não informamos no momento da leitura do arquivo, o Spark não identificou o Schema por padrão e definiu todas as colunas como string.\n",
        "# Para ver o Schema, use o método df_nomes.printSchema().\n",
        "df_nomes.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgGV_z_PM6wi"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDW2S-50LXe1"
      },
      "outputs": [],
      "source": [
        "# Renomear coluna para Nomes\n",
        "df_nomes = df_nomes.withColumnRenamed('_c0', 'Nomes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io51-85cNC-g",
        "outputId": "de4917c6-f28d-4ab2-8e79-6cfa5ded4d7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+\n",
            "|            Nomes|\n",
            "+-----------------+\n",
            "|      Rodger Keys|\n",
            "|       James Cole|\n",
            "|    Vanessa Boyle|\n",
            "|Harriet Berringer|\n",
            "|      Ruby Oleary|\n",
            "|     Trina Norton|\n",
            "|       Joan Bates|\n",
            "|      Carol Avery|\n",
            "|      Page Marthe|\n",
            "|       Wade Brown|\n",
            "+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Nesta etapa, será necessário adicionar código para renomear a coluna para Nomes, imprimir o esquema e mostrar 10 linhas do dataframe.\n",
        "df_nomes.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t59liLG1PEYE"
      },
      "source": [
        "### 3 - Ao dataframe (df_nomes), adicione nova coluna chamada Escolaridade e atribua para cada linha um dos três valores de forma aleatória: Fundamental, Medio ou Superior.\n",
        "\n",
        "Para esta etapa, evite usar funções de iteração, como por exemplo: for, while, entre outras. Dê preferência aos métodos oferecidos para próprio Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M7UwCvqRKeu",
        "outputId": "66d8d80f-7a39-437d-bdab-f1a8f78f8997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------+\n",
            "|            Nomes|Escolaridade|\n",
            "+-----------------+------------+\n",
            "|      Rodger Keys|       Médio|\n",
            "|       James Cole|       Médio|\n",
            "|    Vanessa Boyle|       Médio|\n",
            "|Harriet Berringer|       Médio|\n",
            "|      Ruby Oleary| Fundamental|\n",
            "|     Trina Norton|    Superior|\n",
            "|       Joan Bates|       Médio|\n",
            "|      Carol Avery|    Superior|\n",
            "|      Page Marthe|    Superior|\n",
            "|       Wade Brown|    Superior|\n",
            "+-----------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import rand, when\n",
        "\n",
        "df_nomes = df_nomes.withColumn(\n",
        "    \"Escolaridade\",\n",
        "    when(rand() > 0.66, \"Superior\").when(rand() > 0.33, \"Médio\").otherwise(\"Fundamental\"))\n",
        "\n",
        "df_nomes.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU3MD0AARoZM"
      },
      "source": [
        "### 4 - Ao dataframe (df_nomes), adicione nova coluna chamada Pais e atribua para cada linha o nome de um dos 13 países da América do Sul, de forma aleatória.\n",
        "\n",
        "Para esta etapa, evite usar funções de iteração, como por exemplo: for, while, entre outras. Dê preferência aos métodos oferecidos para próprio Spark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3JLfGOERugs"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from random import choice\n",
        "\n",
        "paises = [\"Argentina\", \"Bolívia\", \"Brasil\", \"Chile\", \"Colômbia\", \"Equador\", \"Guiana\", \"Paraguai\", \"Peru\", \"Suriname\", \"Uruguai\", \"Venezuela\", \"Guiana Francesa\"]\n",
        "\n",
        "def random_country():\n",
        "    return choice(paises)\n",
        "\n",
        "random_country_udf = udf(random_country)\n",
        "\n",
        "df_nomes = df_nomes.withColumn(\"País\", random_country_udf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mO7HC_azSdFC",
        "outputId": "8f3a104e-ce36-4ffe-bd5f-b51a22b1b7ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------+---------------+\n",
            "|            Nomes|Escolaridade|           País|\n",
            "+-----------------+------------+---------------+\n",
            "|      Rodger Keys|       Médio|Guiana Francesa|\n",
            "|       James Cole|       Médio|         Guiana|\n",
            "|    Vanessa Boyle|       Médio|       Paraguai|\n",
            "|Harriet Berringer|       Médio|          Chile|\n",
            "|      Ruby Oleary| Fundamental|       Colômbia|\n",
            "|     Trina Norton|    Superior|        Uruguai|\n",
            "|       Joan Bates|       Médio|         Guiana|\n",
            "|      Carol Avery|    Superior|      Venezuela|\n",
            "|      Page Marthe|    Superior|       Paraguai|\n",
            "|       Wade Brown|    Superior|        Bolívia|\n",
            "+-----------------+------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_nomes.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxxOuYXNTTw2"
      },
      "source": [
        "### 5 - Ao dataframe (df_nomes), adicione nova coluna chamada AnoNascimento e atribua para cada linha um valor de ano entre 1945 e 2010, de forma aleatória."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QQatZDCTQ_g"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import floor, rand\n",
        "\n",
        "df_nomes = df_nomes.withColumn(\"AnoNascimento\", floor(rand() * (2010 - 1945 + 1) + 1945))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t2q189iTLWz",
        "outputId": "2736bd94-0c57-4f67-d878-a78cc42e9975"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----------------+------------+---------------+-------------+\n",
            "|            Nomes|Escolaridade|           País|AnoNascimento|\n",
            "+-----------------+------------+---------------+-------------+\n",
            "|      Rodger Keys|       Médio|Guiana Francesa|         1975|\n",
            "|       James Cole|       Médio|         Guiana|         1951|\n",
            "|    Vanessa Boyle|       Médio|       Paraguai|         1963|\n",
            "|Harriet Berringer|       Médio|          Chile|         1950|\n",
            "|      Ruby Oleary| Fundamental|       Colômbia|         1976|\n",
            "|     Trina Norton|    Superior|        Uruguai|         1986|\n",
            "|       Joan Bates|       Médio|         Guiana|         1972|\n",
            "|      Carol Avery|    Superior|      Venezuela|         2000|\n",
            "|      Page Marthe|    Superior|       Paraguai|         1979|\n",
            "|       Wade Brown|    Superior|        Bolívia|         1985|\n",
            "+-----------------+------------+---------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_nomes.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLY_rL9uU2kD"
      },
      "source": [
        "### 6 - Usando o método select do dataframe (df_nomes), selecione as pessoas que nasceram neste século. Armazene o resultado em outro dataframe chamado df_select e mostre 10 nomes deste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cJt4NtMVAjf",
        "outputId": "32f87fa6-12f1-4da9-e69d-3519f9699236"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-------------+\n",
            "|             Nomes|AnoNascimento|\n",
            "+------------------+-------------+\n",
            "|       Carol Avery|         2000|\n",
            "|    Kimberly Brown|         2004|\n",
            "|       Jessie Jean|         2007|\n",
            "|     Gina Hardnett|         2010|\n",
            "|     Jackie Walker|         2002|\n",
            "|       Gail Hutton|         2003|\n",
            "|       Dottie Keys|         2000|\n",
            "|     Paul Tarleton|         2001|\n",
            "|    Roberto Moretz|         2009|\n",
            "|Socorro Eisenhauer|         2008|\n",
            "+------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_nomes.select('Nomes', 'AnoNascimento').where('AnoNascimento >= 2000').show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn9GP1BTYDnl",
        "outputId": "3f8eac88-9fcc-4451-e794-1619ffbb0a29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-------------+\n",
            "|             Nomes|AnoNascimento|\n",
            "+------------------+-------------+\n",
            "|       Carol Avery|         2000|\n",
            "|    Kimberly Brown|         2004|\n",
            "|       Jessie Jean|         2007|\n",
            "|     Gina Hardnett|         2010|\n",
            "|     Jackie Walker|         2002|\n",
            "|       Gail Hutton|         2003|\n",
            "|       Dottie Keys|         2000|\n",
            "|     Paul Tarleton|         2001|\n",
            "|    Roberto Moretz|         2009|\n",
            "|Socorro Eisenhauer|         2008|\n",
            "+------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_select = df_nomes.select('Nomes', 'AnoNascimento').where('AnoNascimento >= 2000')\n",
        "df_select.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghTjlDBhWboz"
      },
      "source": [
        "### 7 - Usando Spark SQL repita o processo da Pergunta 6. Lembre-se que, para trabalharmos com SparkSQL, precisamos registrar uma tabela temporária e depois executar o comando SQL. Abaixo um exemplo de como executar comandos SQL com SparkSQL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-MpoTkqWAD3",
        "outputId": "6a897f2e-622f-4366-a5e3-79ef1736cea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------------+-------------+\n",
            "|             Nomes|AnoNascimento|\n",
            "+------------------+-------------+\n",
            "|       Carol Avery|         2000|\n",
            "|    Kimberly Brown|         2004|\n",
            "|       Jessie Jean|         2007|\n",
            "|     Gina Hardnett|         2010|\n",
            "|     Jackie Walker|         2002|\n",
            "|       Gail Hutton|         2003|\n",
            "|       Dottie Keys|         2000|\n",
            "|     Paul Tarleton|         2001|\n",
            "|    Roberto Moretz|         2009|\n",
            "|Socorro Eisenhauer|         2008|\n",
            "+------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_nomes.createOrReplaceTempView (\"pessoas\") # Criando tabela temporária\n",
        "spark.sql('select Nomes, AnoNascimento from pessoas\\\n",
        "          where AnoNascimento >= 2000').show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAYYzdvYZLup"
      },
      "source": [
        "### 8 - Usando o método select do Dataframe df_nomes, Conte o número de pessoas que são da geração Millennials (nascidos entre 1980 e 1994) no Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MruwTirYZSlR",
        "outputId": "39ff103c-b719-49b6-8a38-8e9d0603232d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "O número de pessoas da geração Millennials é: 2274109\n"
          ]
        }
      ],
      "source": [
        "df_nomes.where((df_nomes['AnoNascimento'] >= 1980) & (df_nomes['AnoNascimento'] <= 1994)).count()\n",
        "df_cont = df_nomes.where((df_nomes['AnoNascimento'] >= 1980) & (df_nomes['AnoNascimento'] <= 1994)).count()\n",
        "print(f'O número de pessoas da geração Millennials é: {df_cont}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8P-NImWgXj4"
      },
      "source": [
        "### 9 - Repita o processo da Pergunta 8 utilizando Spark SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvaYahmffvgS",
        "outputId": "766863bb-9690-496d-ddd3-9657c32e6272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+\n",
            "|numero_pessoas|\n",
            "+--------------+\n",
            "|       2274109|\n",
            "+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_nomes.createOrReplaceTempView (\"contagem_pessoas\") # Criando tabela temporária\n",
        "spark.sql('select count(*) as numero_pessoas from contagem_pessoas where AnoNascimento >= 1980 and AnoNascimento <= 1994').show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytv3QoDDSNS7"
      },
      "source": [
        "### 10 - Usando Spark SQL, obtenha a quantidade de pessoas de cada país para cada geração abaixo. Armazene o resultado em um novo dataframe e depois mostre todas as linhas em ordem crescente de Pais, Geração e Quantidade\n",
        "\n",
        "- Baby Boomers – nascidos entre 1944 e 1964;\n",
        "\n",
        "- Geração X – nascidos entre 1965 e 1979;4\n",
        "\n",
        "- Millennials (Geração Y) – nascidos entre 1980 e 1994;\n",
        "\n",
        "- Geração Z – nascidos entre 1995 e 2015."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr_LEO7pSYnh"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Criar uma coluna \"Geracao\" com base na coluna \"AnoNascimento\"\n",
        "df_nomes = df_nomes.withColumn(\"Geracao\",\n",
        "                   when((df_nomes[\"AnoNascimento\"] >= 1944) & (df_nomes[\"AnoNascimento\"] <= 1964), \"Baby Boomers\")\n",
        "                   .when((df_nomes[\"AnoNascimento\"] >= 1965) & (df_nomes[\"AnoNascimento\"] <= 1979), \"Geração X\")\n",
        "                   .when((df_nomes[\"AnoNascimento\"] >= 1980) & (df_nomes[\"AnoNascimento\"] <= 1994), \"Millennials (Geração Y)\")\n",
        "                   .when((df_nomes[\"AnoNascimento\"] >= 1995) & (df_nomes[\"AnoNascimento\"] <= 2015), \"Geração Z\")\n",
        "                   .otherwise(\"Outros\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zSfM2XNbt8K",
        "outputId": "44b94807-d255-4f40-cda9-cae7187d43da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+--------------------+------+\n",
            "|           País|             Geracao| count|\n",
            "+---------------+--------------------+------+\n",
            "|      Venezuela|           Geração X|174055|\n",
            "|        Uruguai|           Geração X|175098|\n",
            "|       Colômbia|Millennials (Gera...|175161|\n",
            "|       Paraguai|        Baby Boomers|232606|\n",
            "|Guiana Francesa|           Geração X|174935|\n",
            "|       Suriname|           Geração Z|186090|\n",
            "|         Brasil|           Geração X|174743|\n",
            "|       Colômbia|           Geração Z|186124|\n",
            "|       Colômbia|        Baby Boomers|233214|\n",
            "|       Colômbia|           Geração X|175658|\n",
            "+---------------+--------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Agrupar por Pais e Geracao e contar a quantidade de pessoas\n",
        "agrupar_contar = df_nomes.groupBy(\"País\", \"Geracao\").count()\n",
        "agrupar_contar.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRK0EqSSbyns",
        "outputId": "9275d8d0-b04e-41b5-d4d8-d69cc21a248a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+--------------------+----------+\n",
            "|           País|             Geracao|Quantidade|\n",
            "+---------------+--------------------+----------+\n",
            "|      Venezuela|           Geração X|    174055|\n",
            "|        Uruguai|           Geração X|    175098|\n",
            "|       Colômbia|Millennials (Gera...|    175161|\n",
            "|       Paraguai|        Baby Boomers|    232606|\n",
            "|Guiana Francesa|           Geração X|    174935|\n",
            "|       Suriname|           Geração Z|    186090|\n",
            "|         Brasil|           Geração X|    174743|\n",
            "|       Colômbia|           Geração Z|    186124|\n",
            "|       Colômbia|        Baby Boomers|    233214|\n",
            "|       Colômbia|           Geração X|    175658|\n",
            "+---------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Renomear a coluna \"count\" para \"Quantidade\"\n",
        "renomear_count = agrupar_contar.withColumnRenamed(\"count\", \"Quantidade\")\n",
        "renomear_count.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxY8H-hlb0gL",
        "outputId": "c91bd5f4-213c-442f-b190-6acf0a70b17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+--------------------+----------+\n",
            "|     País|             Geracao|Quantidade|\n",
            "+---------+--------------------+----------+\n",
            "|Argentina|        Baby Boomers|    233273|\n",
            "|Argentina|           Geração X|    174933|\n",
            "|Argentina|           Geração Z|    185951|\n",
            "|Argentina|Millennials (Gera...|    175093|\n",
            "|  Bolívia|        Baby Boomers|    232241|\n",
            "|  Bolívia|           Geração X|    173737|\n",
            "|  Bolívia|           Geração Z|    187002|\n",
            "|  Bolívia|Millennials (Gera...|    174099|\n",
            "|   Brasil|        Baby Boomers|    232864|\n",
            "|   Brasil|           Geração X|    174743|\n",
            "+---------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Ordenar os resultados por Pais, Geracao e Quantidade em ordem crescente\n",
        "# Mostrar resultados\n",
        "ordenar = renomear_count.orderBy(\"País\", \"Geracao\", \"Quantidade\")\n",
        "resultado = ordenar.show(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
