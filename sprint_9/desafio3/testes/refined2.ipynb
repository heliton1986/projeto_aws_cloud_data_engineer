{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Tabela 1\n",
    "table_name1 = \"dim_nome_filme\"\n",
    "datasource1 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name1)\n",
    "dim_nome_filme_df = datasource1.toDF()\n",
    "\n",
    "# Tabela 2\n",
    "table_name2 = \"dim_tempo\"\n",
    "datasource1 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name1)\n",
    "dim_tempo_df = datasource1.toDF()\n",
    "\n",
    "# Tabela 3\n",
    "table_name3 = \"fact_popularidade\"\n",
    "datasource1 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name1)\n",
    "fact_popularidade_df = datasource1.toDF()\n",
    "\n",
    "# Transformação\n",
    "# Realizando a junção das tabelas\n",
    "joined_df = dim_nome_filme_df.join(fact_popularidade_df, \"id_csv\") \\\n",
    "    .join(dim_tempo_df, \"id_csv\") \\\n",
    "    .select(\n",
    "        dim_nome_filme_df.tituloPincipal,\n",
    "        dim_nome_filme_df.genero,\n",
    "        fact_popularidade_df.notamedia,\n",
    "        fact_popularidade_df.numerovotos,\n",
    "        fact_popularidade_df.popularity,\n",
    "        dim_tempo_df.anolancamento,\n",
    "        dim_tempo_df.release_date,\n",
    "        dim_nome_filme_df.overview  \n",
    "    )\n",
    "\n",
    "# Fazendo a agregação e ordenação\n",
    "aggregated_order_df = joined_df.groupBy(\n",
    "    \"anolancamento\",\n",
    "    \"tituloPincipal\",\n",
    "    \"genero\",\n",
    "    \"numerovotos\",\n",
    "    \"popularity\"\n",
    ").agg(\n",
    "    max(\"numerovotos\").alias(\"maior_numerovotos\"),\n",
    "    max(\"popularity\").alias(\"maior_popularity\")\n",
    ").orderBy(\n",
    "    \"maior_numerovotos\",\n",
    "    \"maior_popularity\",\n",
    "    ascending=False\n",
    ").limit(10)\n",
    "\n",
    "# Caminho de saída para o join das dimensoes e fato\n",
    "output_path1 = \"s3://data-lake-heliton/refined/juncao-dimensoes-fato\"\n",
    "joined_df.write.parquet(output_path1, mode=\"overwrite\")\n",
    "\n",
    "# Caminho de saída para agregação e ordenação\n",
    "output_path2 = \"s3://data-lake-heliton/refined/agregacao-ordenacao\"\n",
    "aggregated_order_df.write.parquet(output_path2, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql.functions import from_json, col, explode, array_contains, concat_ws, to_date\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "\n",
    "## @params: [JOB_NAME]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME', 'S3_RAW_PATH', 'S3_TRUSTED_PATH'])\n",
    "\n",
    "conf = SparkConf().setAppName(\"TMDB\").setMaster(\"local\")\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "\n",
    "# # Salva o resultado em formato Parquet no caminho especificado\n",
    "df.write.mode(\"overwrite\").parquet(args['S3_TRUSTED_PATH'])\n",
    "\n",
    "job.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext, SparkConf\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.sql.functions import from_json, col, explode, array_contains, concat_ws, to_date\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "\n",
    "## @params: [JOB_NAME, S3_RAW_PATH, S3_TRUSTED_PATH]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME', 'S3_RAW_PATH', 'S3_TRUSTED_PATH'])\n",
    "\n",
    "conf = SparkConf().setAppName(\"TMDB\").setMaster(\"local\")\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "# Realize o processamento e armazene em um DataFrame processado\n",
    "\n",
    "# Caminho de entrada para os dados brutos\n",
    "input_path = args['S3_RAW_PATH']\n",
    "\n",
    "# Faça a leitura dos dados brutos\n",
    "df_raw = spark.read.parquet(input_path)\n",
    "\n",
    "# Faça as transformações necessárias no DataFrame df_raw para obter o df_processado\n",
    "\n",
    "# Caminho de saída para o DataFrame processado\n",
    "output_path = args['S3_TRUSTED_PATH']\n",
    "\n",
    "# Salve o resultado em formato Parquet no caminho especificado\n",
    "df_processado.write.mode(\"overwrite\").parquet(output_path)\n",
    "\n",
    "job.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crie uma instância do SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Leia a tabela do catálogo do Glue\n",
    "database_name = \"trusted-csv-json-modelagem-refined\"\n",
    "table_name = \"dim_nome_filme\"\n",
    "df_dim_nome_filme = spark.table(f\"{database_name}.{table_name}\")\n",
    "\n",
    "# Faça o mesmo para as outras tabelas\n",
    "table_name2 = \"dim_tempo\"\n",
    "df_dim_tempo = spark.table(f\"{database_name}.{table_name2}\")\n",
    "\n",
    "table_name3 = \"fact_popularidade\"\n",
    "df_fact_popularidade = spark.table(f\"{database_name}.{table_name3}\")\n",
    "\n",
    "# Faça as transformações necessárias\n",
    "# ...\n",
    "\n",
    "# Salve os resultados no novo bucket S3\n",
    "output_bucket = \"s3://seu-novo-bucket/\"\n",
    "output_path = output_bucket + \"caminho-de-saida/\"\n",
    "df_resultado.write.parquet(output_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar o caminho do armazém do Spark\n",
    "spark.conf.set(\"spark.sql.warehouse.dir\", \"s3://seu-bucket/spark-warehouse/\")\n",
    "\n",
    "# Leia a tabela do catálogo do Glue\n",
    "database_name = \"trusted-csv-json-modelagem-refined\"\n",
    "table_name = \"dim_nome_filme\"\n",
    "df_dim_nome_filme = spark.table(f\"{database_name}.{table_name}\")\n",
    "\n",
    "# Faça o mesmo para as outras tabelas\n",
    "table_name2 = \"dim_tempo\"\n",
    "df_dim_tempo = spark.table(f\"{database_name}.{table_name2}\")\n",
    "\n",
    "table_name3 = \"fact_popularidade\"\n",
    "df_fact_popularidade = spark.table(f\"{database_name}.{table_name3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Carregar tabelas como DynamicFrames\n",
    "table_name1 = \"dim_nome_filme\"\n",
    "table_name2 = \"dim_tempo\"\n",
    "table_name3 = \"fact_popularidade\"\n",
    "\n",
    "datasource1 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name1)\n",
    "datasource2 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name2)\n",
    "datasource3 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name3)\n",
    "\n",
    "# Converter DynamicFrames em DataFrames\n",
    "df_dim_nome_filme = datasource1.toDF()\n",
    "df_dim_tempo = datasource2.toDF()\n",
    "df_fact_popularidade = datasource3.toDF()\n",
    "\n",
    "# Realizar a junção das tabelas e selecionar as colunas desejadas\n",
    "joined_df = df_dim_nome_filme.join(df_fact_popularidade, \"id_csv\") \\\n",
    "    .join(df_dim_tempo, \"id_csv\") \\\n",
    "    .select(\n",
    "        df_dim_nome_filme.tituloPincipal,\n",
    "        df_dim_nome_filme.genero,\n",
    "        df_fact_popularidade.notamedia,\n",
    "        df_fact_popularidade.numerovotos,\n",
    "        df_fact_popularidade.popularity,\n",
    "        df_dim_tempo.anolancamento,\n",
    "        df_dim_tempo.release_date,\n",
    "        df_dim_nome_filme.overview  \n",
    "    )\n",
    "\n",
    "# Realizar a agregação e ordenação\n",
    "aggregated_order_df = joined_df.groupBy(\n",
    "    \"anolancamento\",\n",
    "    \"tituloPincipal\",\n",
    "    \"genero\",\n",
    "    \"numerovotos\",\n",
    "    \"popularity\"\n",
    ").agg(\n",
    "    max(\"numerovotos\").alias(\"maior_numerovotos\"),\n",
    "    max(\"popularity\").alias(\"maior_popularity\")\n",
    ").orderBy(\n",
    "    \"maior_numerovotos\",\n",
    "    \"maior_popularity\",\n",
    "    ascending=False\n",
    ").limit(10)\n",
    "\n",
    "# Caminho de saída para o join das dimensões e fato\n",
    "output_path1 = \"s3://data-lake-heliton/refined/juncao-dimensoes-fato\"\n",
    "joined_df.write.parquet(output_path1, mode=\"overwrite\")\n",
    "\n",
    "# Caminho de saída para a agregação e ordenação\n",
    "output_path2 = \"s3://data-lake-heliton/refined/agregacao-ordenacao\"\n",
    "aggregated_order_df.write.parquet(output_path2, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Carregar tabelas como DynamicFrames\n",
    "table_name1 = \"dim_nome_filme\"\n",
    "table_name2 = \"dim_tempo\"\n",
    "table_name3 = \"fact_popularidade\"\n",
    "\n",
    "datasource1 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name1)\n",
    "datasource2 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name2)\n",
    "datasource3 = glueContext.create_dynamic_frame.from_catalog(database=\"trusted-csv-json-modelagem-refined\", table_name=table_name3)\n",
    "\n",
    "# Realizar a junção das tabelas e selecionar as colunas desejadas\n",
    "joined_df = datasource1.join(datasource3, \"id_csv\") \\\n",
    "    .join(datasource2, \"id_csv\") \\\n",
    "    .select(\n",
    "        \"dim_nome_filme.tituloPincipal\",\n",
    "        \"dim_nome_filme.genero\",\n",
    "        \"fact_popularidade.notamedia\",\n",
    "        \"fact_popularidade.numerovotos\",\n",
    "        \"fact_popularidade.popularity\",\n",
    "        \"dim_tempo.anolancamento\",\n",
    "        \"dim_tempo.release_date\",\n",
    "        \"dim_nome_filme.overview\"\n",
    "    )\n",
    "\n",
    "# Realizar a agregação e ordenação\n",
    "aggregated_order_df = joined_df.groupBy(\n",
    "    \"anolancamento\",\n",
    "    \"tituloPincipal\",\n",
    "    \"genero\",\n",
    "    \"numerovotos\",\n",
    "    \"popularity\"\n",
    ").agg(\n",
    "    max(\"numerovotos\").alias(\"maior_numerovotos\"),\n",
    "    max(\"popularity\").alias(\"maior_popularity\")\n",
    ").orderBy(\n",
    "    \"maior_numerovotos\",\n",
    "    \"maior_popularity\",\n",
    "    ascending=False\n",
    ").limit(10)\n",
    "\n",
    "# Caminho de saída para o join das dimensões e fato\n",
    "output_path1 = \"s3://data-lake-heliton/refined/juncao-dimensoes-fato\"\n",
    "glueContext.write_dynamic_frame.from_options(joined_df, connection_type=\"s3\", connection_options={\"path\": output_path1}, format=\"parquet\", transformation_ctx=\"output1\")\n",
    "\n",
    "# Caminho de saída para a agregação e ordenação\n",
    "output_path2 = \"s3://data-lake-heliton/refined/agregacao-ordenacao\"\n",
    "glueContext.write_dynamic_frame.from_options(aggregated_order_df, connection_type=\"s3\", connection_options={\"path\": output_path2}, format=\"parquet\", transformation_ctx=\"output2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Especifique os detalhes da tabela\n",
    "database_name = \"trusted-csv-json-modelagem-refined\"\n",
    "table_name = \"dim_nome_filme\"\n",
    "table_path = \"s3://data-lake-heliton/trusted/csv_imdb/movies/\"  # Especifique o caminho correto para os dados\n",
    "\n",
    "# Crie a tabela no Glue Catalog\n",
    "glueContext.create_dynamic_frame.from_catalog(database=database_name, table_name=table_name, transformation_ctx=\"datasource0\")\n",
    "datasource0.toDF().write.format(\"parquet\").mode(\"overwrite\").save(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crie a sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Create Tables\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Especifique os detalhes da tabela\n",
    "database_name = \"trusted-csv-json-modelagem-refined\"\n",
    "table_name = \"dim_nome_filme\"\n",
    "\n",
    "# Crie o DataFrame correspondente à visualização\n",
    "df_dim_nome_filme = spark.sql(\"SELECT tb_csv.id as id_csv, \"\n",
    "                              \"tb_json.id as id_json, \"\n",
    "                              \"tb_csv.tituloPincipal, \"\n",
    "                              \"tb_csv.genero, \"\n",
    "                              \"tb_json.overview \"\n",
    "                              \"FROM tb_csv \"\n",
    "                              \"JOIN tb_json \"\n",
    "                              \"ON tb_csv.titulopincipal = tb_json.title\")\n",
    "\n",
    "# Salve o DataFrame como uma tabela no Glue Catalog\n",
    "df_dim_nome_filme.write \\\n",
    "    .format(\"parquet\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"path\", f\"s3://data-lake-heliton/trusted/csv_imdb/movies/{table_name}\") \\\n",
    "    .saveAsTable(f\"{database_name}.{table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Carregar as tabelas existentes\n",
    "table_name1 = \"tb_csv\"\n",
    "table_name2 = \"tb_json\"\n",
    "\n",
    "df_tb_csv = spark.table(table_name1)\n",
    "df_tb_json = spark.table(table_name2)\n",
    "\n",
    "# Criar as dimensões e a tabela de fato\n",
    "df_dim_nome_filme = df_tb_csv.join(df_tb_json, df_tb_csv[\"titulopincipal\"] == df_tb_json[\"title\"]) \\\n",
    "    .select(df_tb_csv[\"id\"].alias(\"id_csv\"),\n",
    "            df_tb_json[\"id\"].alias(\"id_json\"),\n",
    "            df_tb_csv[\"tituloPincipal\"],\n",
    "            df_tb_csv[\"genero\"],\n",
    "            df_tb_json[\"overview\"])\n",
    "\n",
    "df_dim_tempo = df_tb_csv.join(df_tb_json, df_tb_csv[\"titulopincipal\"] == df_tb_json[\"title\"]) \\\n",
    "    .select(df_tb_csv[\"id\"].alias(\"id_csv\"),\n",
    "            df_tb_json[\"id\"].alias(\"id_json\"),\n",
    "            df_tb_csv[\"anoLancamento\"],\n",
    "            df_tb_json[\"release_date\"])\n",
    "\n",
    "df_fact_popularidade = df_tb_csv.join(df_tb_json, df_tb_csv[\"titulopincipal\"] == df_tb_json[\"title\"]) \\\n",
    "    .select(df_tb_csv[\"id\"].alias(\"id_csv\"),\n",
    "            df_tb_json[\"id\"].alias(\"id_json\"),\n",
    "            df_tb_csv[\"notaMedia\"],\n",
    "            df_tb_csv[\"numeroVotos\"],\n",
    "            df_tb_json[\"popularity\"])\n",
    "\n",
    "# Realizar operações com as dimensões e a tabela de fato\n",
    "# ...\n",
    "\n",
    "# Salvar as dimensões e a tabela de fato em um local de sua escolha\n",
    "output_path_dim_nome_filme = \"s3://data-lake-heliton/refined/dim_nome_filme/\"\n",
    "output_path_dim_tempo = \"s3://data-lake-heliton/refined/dim_tempo/\"\n",
    "output_path_fact_popularidade = \"s3://data-lake-heliton/refined//fact_popularidade/\"\n",
    "\n",
    "df_dim_nome_filme.write.parquet(output_path_dim_nome_filme, mode=\"overwrite\")\n",
    "df_dim_tempo.write.parquet(output_path_dim_tempo, mode=\"overwrite\")\n",
    "df_fact_popularidade.write.parquet(output_path_fact_popularidade, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
