{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crie uma instância do SparkContext\n",
    "sc = SparkContext()\n",
    "\n",
    "# Crie uma instância do GlueContext\n",
    "glueContext = GlueContext(sc)\n",
    "\n",
    "# Crie uma instância do SparkSession\n",
    "spark = glueContext.spark_session\n",
    "\n",
    "# Leia os dados da tabela do Data Catalog\n",
    "table_name = \"seu-nome-de-tabela-no-data-catalog\"\n",
    "datasource = glueContext.create_dynamic_frame.from_catalog(database = \"seu-nome-de-banco-de-dados-no-data-catalog\", table_name = table_name)\n",
    "\n",
    "# Converta o DynamicFrame para DataFrame\n",
    "df = datasource.toDF()\n",
    "\n",
    "# Faça o processamento conforme necessário\n",
    "df_processado = df.select(\"coluna1\", \"coluna2\", ...)\n",
    "\n",
    "# Salve os resultados no novo bucket S3\n",
    "output_bucket = \"s3://seu-novo-bucket/\"\n",
    "output_path = output_bucket + \"caminho-de-saida/\"\n",
    "df_processado.write.parquet(output_path, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Inicialize a sessão do Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Exemplo PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Carregue os resultados das dimensões do Athena usando o PySpark\n",
    "dim_nome_filme_df = spark.sql(\"SELECT * FROM dim_nome_filme\")\n",
    "fact_popularidade_df = spark.sql(\"SELECT * FROM fact_popularidade\")\n",
    "dim_tempo_df = spark.sql(\"SELECT * FROM dim_tempo\")\n",
    "\n",
    "# Especifique o caminho para o novo bucket S3 onde deseja salvar os dados\n",
    "novo_bucket_s3 = \"s3://seu-novo-bucket/\"\n",
    "\n",
    "# Salve os dados das dimensões no novo bucket S3\n",
    "dim_nome_filme_df.write.parquet(novo_bucket_s3 + \"dim_nome_filme\")\n",
    "fact_popularidade_df.write.parquet(novo_bucket_s3 + \"fact_popularidade\")\n",
    "dim_tempo_df.write.parquet(novo_bucket_s3 + \"dim_tempo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import max\n",
    "\n",
    "# Inicialize a sessão do Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Exemplo PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Leia os dados das dimensões e fatos como DataFrames\n",
    "dim_nome_filme_df = spark.table(\"dim_nome_filme\")\n",
    "fact_popularidade_df = spark.table(\"fact_popularidade\")\n",
    "dim_tempo_df = spark.table(\"dim_tempo\")\n",
    "\n",
    "# Junte as dimensões e fatos\n",
    "joined_df = dim_nome_filme_df.join(fact_popularidade_df, \"id_csv\") \\\n",
    "    .join(dim_tempo_df, \"id_csv\") \\\n",
    "    .select(\n",
    "        dim_nome_filme_df.tituloPincipal,\n",
    "        dim_nome_filme_df.genero,\n",
    "        fact_popularidade_df.notamedia,\n",
    "        fact_popularidade_df.numerovotos,\n",
    "        fact_popularidade_df.popularity,\n",
    "        dim_tempo_df.anolancamento,\n",
    "        dim_tempo_df.release_date,\n",
    "        dim_nome_filme_df.overview\n",
    "    )\n",
    "\n",
    "# Realize o agrupamento\n",
    "aggregated_df = joined_df.groupBy(\"anolancamento\") \\\n",
    "    .agg(\n",
    "        max(\"numerovotos\").alias(\"maior_numerovotos\"),\n",
    "        max(\"popularity\").alias(\"maior_popularity\")\n",
    "    )\n",
    "\n",
    "# Ordene os resultados pelo ano de lançamento mais recente\n",
    "result_df = aggregated_df.orderBy(\"anolancamento\", ascending=False)\n",
    "\n",
    "# Exiba os resultados\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realize o agrupamento\n",
    "aggregated_df = joined_df.groupBy(\"anolancamento\") \\\n",
    "    .agg(\n",
    "        max(\"numerovotos\").alias(\"maior_numerovotos\"),\n",
    "        max(\"popularity\").alias(\"maior_popularity\")\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
