{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UchvA-uXt-yj",
        "outputId": "dc204235-1521-4d10-907d-f673604cfc53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Cria a sessão do Spark\n",
        "spark = SparkSession.builder.appName(\"CSV to Parquet\").getOrCreate()\n",
        "\n",
        "# Caminho do arquivo CSV de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV\n",
        "data_frame = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \"|\").load(input_path)\n",
        "\n",
        "# Remove as colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", data_frame[\"anoLancamento\"].cast(\"integer\"))\n",
        "data_frame = data_frame.withColumn(\"tempoMinutos\", data_frame[\"tempoMinutos\"].cast(\"integer\"))\n",
        "data_frame = data_frame.withColumn(\"notaMedia\", data_frame[\"notaMedia\"].cast(\"float\"))\n",
        "data_frame = data_frame.withColumn(\"numeroVotos\", data_frame[\"numeroVotos\"].cast(\"integer\"))\n",
        "data_frame = data_frame.withColumn(\"anoNascimento\", data_frame[\"anoNascimento\"].cast(\"integer\"))\n",
        "\n",
        "# Mostra o resultado em DataFrame\n",
        "data_frame.show()\n",
        "\n",
        "# Encerra a sessão do Spark\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "_ATtVvlAuBV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Cria a sessão do Spark\n",
        "spark = SparkSession.builder.appName(\"CSV to Parquet\").getOrCreate()\n",
        "\n",
        "# Caminho do arquivo CSV de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV\n",
        "data_frame = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"delimiter\", \"|\").load(input_path)\n",
        "\n",
        "# Remove as colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", data_frame[\"anoLancamento\"].cast(\"integer\"))\n",
        "data_frame = data_frame.withColumn(\"tempoMinutos\", data_frame[\"tempoMinutos\"].cast(\"integer\"))\n",
        "data_frame = data_frame.withColumn(\"notaMedia\", data_frame[\"notaMedia\"].cast(\"float\"))\n",
        "data_frame = data_frame.withColumn(\"numeroVotos\", data_frame[\"numeroVotos\"].cast(\"integer\"))\n",
        "data_frame = data_frame.withColumn(\"anoNascimento\", data_frame[\"anoNascimento\"].cast(\"integer\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.na.replace(\"\\\\N\", None)\n",
        "\n",
        "# Mostra o resultado em DataFrame\n",
        "data_frame.show()\n",
        "\n",
        "# Encerra a sessão do Spark\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "Pu-xQC5dvc5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropando as colunas \"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\""
      ],
      "metadata": {
        "id": "vwl7jF_ndBEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define o número máximo de linhas a serem exibidas\n",
        "pd.set_option('display.max_rows', 100)  # Define 1000 como o número máximo de linhas a serem exibidas\n",
        "\n",
        "# Caminho do arquivo CSV de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando pandas\n",
        "data_frame = pd.read_csv(input_path, delimiter=\"|\")\n",
        "\n",
        "# Remove as colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame[\"anoLancamento\"] = pd.to_numeric(data_frame[\"anoLancamento\"], errors=\"coerce\")\n",
        "data_frame[\"tempoMinutos\"] = pd.to_numeric(data_frame[\"tempoMinutos\"], errors=\"coerce\")\n",
        "data_frame[\"notaMedia\"] = pd.to_numeric(data_frame[\"notaMedia\"], errors=\"coerce\")\n",
        "data_frame[\"numeroVotos\"] = pd.to_numeric(data_frame[\"numeroVotos\"], errors=\"coerce\")\n",
        "data_frame[\"anoNascimento\"] = pd.to_numeric(data_frame[\"anoNascimento\"], errors=\"coerce\")\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (NaN)\n",
        "data_frame.replace(\"\\\\N\", pd.NA, inplace=True)\n",
        "\n",
        "# Mostra o resultado em DataFrame\n",
        "data_frame.head(20)\n",
        "\n",
        "# # Salva o DataFrame em formato Parquet (opcional)\n",
        "# output_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.parquet\"\n",
        "# data_frame.to_parquet(output_path, engine=\"pyarrow\")"
      ],
      "metadata": {
        "id": "9hMv9Qzqv6r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropando registros NA"
      ],
      "metadata": {
        "id": "Np6Js_k8dPeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define o número máximo de linhas a serem exibidas\n",
        "pd.set_option('display.max_rows', 100)  # Define 1000 como o número máximo de linhas a serem exibidas\n",
        "\n",
        "# Caminho do arquivo CSV de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando pandas\n",
        "data_frame = pd.read_csv(input_path, delimiter=\"|\")\n",
        "\n",
        "# Remove as colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame[\"anoLancamento\"] = pd.to_numeric(data_frame[\"anoLancamento\"], errors=\"coerce\")\n",
        "data_frame[\"tempoMinutos\"] = pd.to_numeric(data_frame[\"tempoMinutos\"], errors=\"coerce\")\n",
        "data_frame[\"notaMedia\"] = pd.to_numeric(data_frame[\"notaMedia\"], errors=\"coerce\")\n",
        "data_frame[\"numeroVotos\"] = pd.to_numeric(data_frame[\"numeroVotos\"], errors=\"coerce\")\n",
        "data_frame[\"anoNascimento\"] = pd.to_numeric(data_frame[\"anoNascimento\"], errors=\"coerce\")\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (NaN)\n",
        "data_frame.replace(\"\\\\N\", pd.NA, inplace=True)\n",
        "\n",
        "# Dropa os registros que possuem valores NA\n",
        "data_frame.dropna(inplace=True)\n",
        "\n",
        "# Mostra o resultado em DataFrame\n",
        "data_frame.head(10)\n"
      ],
      "metadata": {
        "id": "cqttwr-bw9Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remover duplicados"
      ],
      "metadata": {
        "id": "nVJKRkyHdYj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define o número máximo de linhas a serem exibidas\n",
        "pd.set_option('display.max_rows', 100)  # Define 1000 como o número máximo de linhas a serem exibidas\n",
        "\n",
        "# Caminho do arquivo CSV de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando pandas\n",
        "data_frame = pd.read_csv(input_path, delimiter=\"|\")\n",
        "\n",
        "# Remove as colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame[\"anoLancamento\"] = pd.to_numeric(data_frame[\"anoLancamento\"], errors=\"coerce\")\n",
        "data_frame[\"tempoMinutos\"] = pd.to_numeric(data_frame[\"tempoMinutos\"], errors=\"coerce\")\n",
        "data_frame[\"notaMedia\"] = pd.to_numeric(data_frame[\"notaMedia\"], errors=\"coerce\")\n",
        "data_frame[\"numeroVotos\"] = pd.to_numeric(data_frame[\"numeroVotos\"], errors=\"coerce\")\n",
        "data_frame[\"anoNascimento\"] = pd.to_numeric(data_frame[\"anoNascimento\"], errors=\"coerce\")\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (NaN)\n",
        "data_frame.replace(\"\\\\N\", pd.NA, inplace=True)\n",
        "\n",
        "# Dropa os registros que possuem valores NA\n",
        "data_frame.dropna(inplace=True)\n",
        "\n",
        "# Remove os IDs duplicados\n",
        "data_frame.drop_duplicates(subset=\"id\", keep=\"first\", inplace=True)\n",
        "\n",
        "# Mostra o resultado em DataFrame\n",
        "data_frame.head(100)\n"
      ],
      "metadata": {
        "id": "7S1QHZ1YdZHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remover duplicados Pyspark"
      ],
      "metadata": {
        "id": "W32JvqJ6lp21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Cria uma sessão Spark\n",
        "spark = SparkSession.builder.appName(\"Pandas para PySpark\").getOrCreate()\n",
        "\n",
        "# Define o caminho de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando Spark\n",
        "data_frame = spark.read.option(\"delimiter\", \"|\").csv(input_path, header=True)\n",
        "\n",
        "# Remove colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", col(\"anoLancamento\").cast(\"int\")) \\\n",
        "    .withColumn(\"tempoMinutos\", col(\"tempoMinutos\").cast(\"int\")) \\\n",
        "    .withColumn(\"notaMedia\", col(\"notaMedia\").cast(\"float\")) \\\n",
        "    .withColumn(\"numeroVotos\", col(\"numeroVotos\").cast(\"int\")) \\\n",
        "    .withColumn(\"anoNascimento\", col(\"anoNascimento\").cast(\"int\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.replace(\"\\\\N\", None)\n",
        "\n",
        "# Remove registros com valores nulos\n",
        "data_frame = data_frame.na.drop()\n",
        "\n",
        "# Remove IDs duplicados\n",
        "data_frame = data_frame.dropDuplicates([\"id\"])\n",
        "\n",
        "# Mostra o resultado como um DataFrame\n",
        "data_frame.show(100)\n"
      ],
      "metadata": {
        "id": "QMpshSAjk6ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apenas genero de Horror"
      ],
      "metadata": {
        "id": "10KSNQkJfaCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define o número máximo de linhas a serem exibidas\n",
        "pd.set_option('display.max_rows', 100)  # Define 1000 como o número máximo de linhas a serem exibidas\n",
        "\n",
        "# Caminho do arquivo CSV de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando pandas\n",
        "data_frame = pd.read_csv(input_path, delimiter=\"|\")\n",
        "\n",
        "# Remove as colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame.drop(columns_to_drop, axis=1, inplace=True)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame[\"anoLancamento\"] = pd.to_numeric(data_frame[\"anoLancamento\"], errors=\"coerce\")\n",
        "data_frame[\"tempoMinutos\"] = pd.to_numeric(data_frame[\"tempoMinutos\"], errors=\"coerce\")\n",
        "data_frame[\"notaMedia\"] = pd.to_numeric(data_frame[\"notaMedia\"], errors=\"coerce\")\n",
        "data_frame[\"numeroVotos\"] = pd.to_numeric(data_frame[\"numeroVotos\"], errors=\"coerce\")\n",
        "data_frame[\"anoNascimento\"] = pd.to_numeric(data_frame[\"anoNascimento\"], errors=\"coerce\")\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (NaN)\n",
        "data_frame.replace(\"\\\\N\", pd.NA, inplace=True)\n",
        "\n",
        "# Dropa os registros que possuem valores NA\n",
        "data_frame.dropna(inplace=True)\n",
        "\n",
        "# Remove os IDs duplicados\n",
        "data_frame.drop_duplicates(subset=\"id\", keep=\"first\", inplace=True)\n",
        "\n",
        "# Filtra os registros por gênero \"Terror\" e \"Horror\"\n",
        "terror_horror_movies = data_frame[data_frame[\"genero\"].str.contains(\"Horror\")]\n",
        "# terror_horror_movies = data_frame.where(col(\"genero\").contains(\"Horror\"))\n",
        "\n",
        "\n",
        "# Mostra o resultado em DataFrame\n",
        "data_frame.head(50)\n"
      ],
      "metadata": {
        "id": "wUJt9AB9fbT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apenas genero de Horror Pyspark"
      ],
      "metadata": {
        "id": "cBftMrFgsLi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower, array_contains\n",
        "\n",
        "# Cria uma sessão Spark\n",
        "spark = SparkSession.builder.appName(\"Pandas para PySpark\").getOrCreate()\n",
        "\n",
        "# Define o caminho de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando Spark\n",
        "data_frame = spark.read.option(\"delimiter\", \"|\").csv(input_path, header=True)\n",
        "\n",
        "# Remove colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", col(\"anoLancamento\").cast(\"int\")) \\\n",
        "    .withColumn(\"notaMedia\", col(\"notaMedia\").cast(\"float\")) \\\n",
        "    .withColumn(\"numeroVotos\", col(\"numeroVotos\").cast(\"int\")) \\\n",
        "    .withColumn(\"anoNascimento\", col(\"anoNascimento\").cast(\"int\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.replace(\"\\\\N\", None)\n",
        "\n",
        "# Remove registros com valores nulos\n",
        "data_frame = data_frame.na.drop()\n",
        "\n",
        "# Remove IDs duplicados\n",
        "data_frame = data_frame.dropDuplicates([\"id\"])\n",
        "\n",
        "# Filtra os registros que contenham na coluna \"genero\" os valores \"terror\" e \"horror\"\n",
        "# data_frame_genero = data_frame.where(col(\"genero\").contains(\"Horror\"))\n",
        "\n",
        "data_frame_genero = data_frame.where(col(\"genero\").contains(\"Horror\")).select(\"id\", \"tituloPincipal\", \"anoLancamento\", \"genero\", \"notaMedia\", \"numeroVotos\")\n",
        "\n",
        "# Mostra o resultado como um DataFrame\n",
        "data_frame_genero.show(10)"
      ],
      "metadata": {
        "id": "2kCtpejSmGQn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f727fd5-0054-4b37-a5d4-99cfda587071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+-------------+--------------------+---------+-----------+\n",
            "|       id|      tituloPincipal|anoLancamento|              genero|notaMedia|numeroVotos|\n",
            "+---------+--------------------+-------------+--------------------+---------+-----------+\n",
            "|tt0003419|The Student of Pr...|         1913|Drama,Fantasy,Horror|      6.4|       2171|\n",
            "|tt0004121|The Hound of the ...|         1914|Crime,Horror,Mystery|      5.5|        119|\n",
            "|tt0005231|The Hound of the ...|         1915|Crime,Horror,Mystery|      3.2|         41|\n",
            "|tt0005951|    Satan's Rhapsody|         1917|Drama,Fantasy,Horror|      6.8|        748|\n",
            "|tt0006820| Homunculus, 1. Teil|         1916|       Horror,Sci-Fi|      5.9|        101|\n",
            "|tt0007183| The Queen of Spades|         1916|Drama,Fantasy,Horror|      6.7|        761|\n",
            "|tt0007983|              Furcht|         1917|              Horror|      6.2|        184|\n",
            "|tt0008099|Hilde Warren und ...|         1917|              Horror|      5.8|        128|\n",
            "|tt0008252|            Malombra|         1917|Drama,Horror,Mystery|      6.0|        125|\n",
            "|tt0008826|             Alraune|         1919|       Horror,Sci-Fi|      5.6|         54|\n",
            "+---------+--------------------+-------------+--------------------+---------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_genero.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnV2D8OQCUEe",
        "outputId": "7f3588d8-1f1f-47c6-f07a-cdf21dc04771"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13025"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_genero.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aV1IoKjd5f48",
        "outputId": "b4b3c2f1-d121-4e9e-c961-04a36351dfd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- tituloPincipal: string (nullable = true)\n",
            " |-- anoLancamento: integer (nullable = true)\n",
            " |-- genero: string (nullable = true)\n",
            " |-- notaMedia: float (nullable = true)\n",
            " |-- numeroVotos: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converter em pastas particionadas para csv e visualizar o schema das colunas"
      ],
      "metadata": {
        "id": "7NyJ48NtxG_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower\n",
        "from datetime import datetime\n",
        "\n",
        "# Cria uma sessão Spark\n",
        "spark = SparkSession.builder.appName(\"Pandas para PySpark\").getOrCreate()\n",
        "\n",
        "# Define o caminho de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando Spark\n",
        "data_frame = spark.read.option(\"delimiter\", \"|\").csv(input_path, header=True)\n",
        "\n",
        "# Remove colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\", \"personagem\", \"tempoMinutos\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", col(\"anoLancamento\").cast(\"int\")) \\\n",
        "    .withColumn(\"notaMedia\", col(\"notaMedia\").cast(\"float\")) \\\n",
        "    .withColumn(\"numeroVotos\", col(\"numeroVotos\").cast(\"int\")) \\\n",
        "    .withColumn(\"anoNascimento\", col(\"anoNascimento\").cast(\"int\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.replace(\"\\\\N\", None)\n",
        "\n",
        "# Remove registros com valores nulos\n",
        "data_frame = data_frame.na.drop()\n",
        "\n",
        "# Remove IDs duplicados\n",
        "data_frame = data_frame.dropDuplicates([\"id\"])\n",
        "\n",
        "# Filtra os registros que contenham na coluna \"genero\" os valores \"terror\" e \"horror\"\n",
        "# data_frame_genero = data_frame.filter((lower(col(\"genero\")) == \"horror\"))\n",
        "data_frame_genero = data_frame.where(col(\"genero\").contains(\"Horror\"))\n",
        "\n",
        "# Define o caminho de saída\n",
        "now = datetime.now()\n",
        "output_path = f\"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/trusted/csv/movies/output_csv/{now.year}/{now.month}/{now.day}/\"\n",
        "\n",
        "# # Salva o resultado em um arquivo CSV no caminho especificado\n",
        "# data_frame_genero.write.csv(output_path, header=True)\n",
        "\n",
        "\n",
        "# Salva o resultado em um único arquivo CSV no caminho especificado\n",
        "data_frame_genero.write.mode(\"overwrite\").csv(output_path, header=True)\n",
        "\n",
        "import os\n",
        "\n",
        "# Cria o diretório se ele não existir\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "# print(data_frame_genero.schema)\n",
        "# print(data_frame_genero.show(50))\n",
        "# Salva o resultado em um único arquivo CSV no caminho especificado\n",
        "data_frame_pandas = data_frame_genero.toPandas()\n",
        "data_frame_pandas.to_csv(output_path + \"/result.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "SLV1J3zys5R5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_genero.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5phb4UQVrLoo",
        "outputId": "50d14c6a-8b2f-434f-b156-0dd92503303f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13722"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## codigo csv IMDB para parquet particionado"
      ],
      "metadata": {
        "id": "S0hcOgUXx9Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lower\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Cria uma sessão Spark\n",
        "spark = SparkSession.builder.appName(\"Pandas para PySpark\").getOrCreate()\n",
        "\n",
        "# Define o caminho de entrada\n",
        "input_path = \"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando Spark\n",
        "data_frame = spark.read.option(\"delimiter\", \"|\").csv(input_path, header=True)\n",
        "\n",
        "# Remove colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\", \"personagem\", \"tempoMinutos\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", col(\"anoLancamento\").cast(\"int\")) \\\n",
        "    .withColumn(\"notaMedia\", col(\"notaMedia\").cast(\"float\")) \\\n",
        "    .withColumn(\"numeroVotos\", col(\"numeroVotos\").cast(\"int\")) \\\n",
        "    .withColumn(\"anoNascimento\", col(\"anoNascimento\").cast(\"int\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.replace(\"\\\\N\", None)\n",
        "\n",
        "# Remove registros com valores nulos\n",
        "data_frame = data_frame.na.drop()\n",
        "\n",
        "# Remove IDs duplicados\n",
        "data_frame = data_frame.dropDuplicates([\"id\"])\n",
        "\n",
        "# Filtra os registros que contenham na coluna \"genero\" os valores \"terror\" e \"horror\"\n",
        "data_frame_genero = data_frame.where(col(\"genero\").contains(\"Horror\"))\n",
        "\n",
        "# Cria o diretório se ele não existir\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Define o caminho de saída\n",
        "now = datetime.now()\n",
        "output_path = f\"/content/drive/MyDrive/Colab Notebooks/desafio_parte3/trusted/csv/movies/output_parquet/{now.year}/{now.month}/{now.day}\"\n",
        "\n",
        "\n",
        "# Salva o resultado em formato Parquet no caminho especificado\n",
        "data_frame_genero.write.mode(\"overwrite\").parquet(output_path)\n"
      ],
      "metadata": {
        "id": "JnqMPrLwCozG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_genero.show(100)"
      ],
      "metadata": {
        "id": "WYSzjBHWs30j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_frame_genero.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYtYjUldxMyJ",
        "outputId": "035e335f-cd00-4ef9-bbd0-375c9f01ec26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14643"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Para AWS Glue"
      ],
      "metadata": {
        "id": "DQCHIsGOvLUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.context import GlueContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Cria uma sessão Spark\n",
        "spark_context = SparkContext()\n",
        "glue_context = GlueContext(spark_context)\n",
        "spark = glue_context.spark_session\n",
        "\n",
        "# Define o caminho de entrada\n",
        "input_path = \"s3://data-lake-heliton/input/movies.csv\"\n",
        "\n",
        "# Lê o arquivo CSV usando Spark\n",
        "data_frame = spark.read.option(\"delimiter\", \"|\").csv(input_path, header=True)\n",
        "\n",
        "# Remove colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\", \"personagem\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", col(\"anoLancamento\").cast(\"int\")) \\\n",
        "    .withColumn(\"tempoMinutos\", col(\"tempoMinutos\").cast(\"int\")) \\\n",
        "    .withColumn(\"notaMedia\", col(\"notaMedia\").cast(\"float\")) \\\n",
        "    .withColumn(\"numeroVotos\", col(\"numeroVotos\").cast(\"int\")) \\\n",
        "    .withColumn(\"anoNascimento\", col(\"anoNascimento\").cast(\"int\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.replace(\"\\\\N\", None)\n",
        "\n",
        "# Remove registros com valores nulos\n",
        "data_frame = data_frame.na.drop()\n",
        "\n",
        "# Remove IDs duplicados\n",
        "data_frame = data_frame.dropDuplicates([\"id\"])\n",
        "\n",
        "# Filtra os registros que contenham na coluna \"genero\" os valores \"horror\" e \"terror\"\n",
        "ddata_frame_genero = data_frame.where(col(\"genero\").contains(\"Horror\"))\n",
        "\n",
        "# Define o caminho de saída\n",
        "now = datetime.now()\n",
        "output_path = f\"s3://data-lake-heliton/trusted/csv_imdb/parquet/{now.year}/{now.month}/{now.day}\"\n",
        "\n",
        "# Salva o resultado em formato Parquet no caminho especificado\n",
        "data_frame_genero.write.mode(\"overwrite\").parquet(output_path)\n"
      ],
      "metadata": {
        "id": "cDDjJLbStz8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pyspark.context import SparkContext\n",
        "from awsglue.context import GlueContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "import sys\n",
        "\n",
        "# Cria uma sessão Spark\n",
        "spark_context = SparkContext()\n",
        "glue_context = GlueContext(spark_context)\n",
        "spark = glue_context.spark_session\n",
        "\n",
        "# Obter os argumentos resolvidos\n",
        "args = getResolvedOptions(sys.argv, ['JOB_NAME', 'S3_INPUT_PATH', 'S3_TARGET_PATH'])\n",
        "\n",
        "# Define o caminho de entrada e o caminho de saída\n",
        "input_path = args['S3_INPUT_PATH']\n",
        "output_path = args['S3_TARGET_PATH']\n",
        "\n",
        "# Lê o arquivo CSV usando Spark\n",
        "data_frame = spark.read.option(\"delimiter\", \"|\").csv(input_path, header=True)\n",
        "\n",
        "# Remove colunas indesejadas\n",
        "columns_to_drop = [\"anoFalecimento\", \"profissao\", \"titulosMaisConhecidos\", \"personagem\"]\n",
        "data_frame = data_frame.drop(*columns_to_drop)\n",
        "\n",
        "# Converte os tipos de dados necessários\n",
        "data_frame = data_frame.withColumn(\"anoLancamento\", col(\"anoLancamento\").cast(\"int\")) \\\n",
        "    .withColumn(\"tempoMinutos\", col(\"tempoMinutos\").cast(\"int\")) \\\n",
        "    .withColumn(\"notaMedia\", col(\"notaMedia\").cast(\"float\")) \\\n",
        "    .withColumn(\"numeroVotos\", col(\"numeroVotos\").cast(\"int\")) \\\n",
        "    .withColumn(\"anoNascimento\", col(\"anoNascimento\").cast(\"int\"))\n",
        "\n",
        "# Substitui os valores \"\\N\" por nulos (None)\n",
        "data_frame = data_frame.replace(\"\\\\N\", None)\n",
        "\n",
        "# Remove registros com valores nulos\n",
        "data_frame = data_frame.na.drop()\n",
        "\n",
        "# Remove IDs duplicados\n",
        "data_frame = data_frame.dropDuplicates([\"id\"])\n",
        "\n",
        "# Filtra os registros que contenham na coluna \"genero\" os valores \"horror\" e \"terror\"\n",
        "data_frame_genero = data_frame.filter((col(\"genero\").contains(\"horror\")) | (col(\"genero\").contains(\"terror\")))\n",
        "\n",
        "# Salva o resultado em formato Parquet no caminho especificado\n",
        "data_frame_genero.write.mode(\"overwrite\").parquet(output_path)\n",
        "\n",
        "# s3://data-lake-heliton/RAW/Local/CSV/Movies/2023/6/15/"
      ],
      "metadata": {
        "id": "gD3S1-KE2A-y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}