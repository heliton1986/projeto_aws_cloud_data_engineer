# Projeto AWS Cloud Data Engineer-

## Apresentação

- Sou Heliton, estou cursando o 5º semestre da graduação tecnológica de **Big Data e Inteligência Analítica** da ***Uniasselvi***.
- Moro em Uberaba, que é localizado no Triângulo Mineiro - Minas Gerais.
- Na área de tecnologia, tenho estudado Python, Linux, Docker, MySql, PostgreSql, Git, Databricks, Hadoop e alguns serviços da AWS:
    - RDS
    - DMS
    - S3
    - EMR
    - Glue
    - Athena

- Hobbies:
    - Ouvir música;
    - Ler;
    - Sair com amigos/familiares;
    - Estudar.

- Desafio Parte I: Criar código Python que carrega arquivos CSV para a Nuvem utilizando as técnicas de ETL

- Desafio Parte II: Fazer ingestão dos dados da API do Tmdb com Python usando lib do Boto3 para o AWS S3 da lista de filmes para a camada Raw.

- Criação de Jobs em Pyspark para fazer ingestão, transformação dos arquivos csv e json e carregamento destes em formato parquet na camada Trusted no S3 usando Aws Glue;
- Criação do Database para fazer o catálogo de dados e modelagem dimensional via Athena dos arquivos parquets criados na camada Trusted;
- Criação de Jobs em Pyspark para fazer ingestão, transformação das tabelas e views das dimensões e fatos da camada Trusted e carregamento destes em formato parquet na camada Refined no S3 usando Aws Glue;
- Criação do Database para fazer o catálogo de dados e modelagem dimensional via Athena dos arquivos parquets criados na camada Refined;














